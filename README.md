<a id="top"></a>

# DataPulse (æ•°æ®è„‰æ) Intelligence Hub

> è‹±æ–‡åï¼šDataPulseï½œä¸­æ–‡åï¼šæ•°æ®è„‰æ  
> ç‚¹å‡»åˆ‡æ¢åˆ°å¯¹åº”è¯­è¨€ç‰ˆæœ¬ï¼š  
> <a href="./README_CN.md">ğŸ‡¨ğŸ‡³ ä¸­æ–‡ç‰ˆ</a> | <a href="./README_EN.md">ğŸ‡ºğŸ‡¸ English version</a>

<details open>
<summary><b>ğŸ‡¨ğŸ‡³ ä¸­æ–‡</b></summary>

## æ•°æ®è„‰æï¼ˆDataPulseï¼‰æ ¸å¿ƒç›®æ ‡

åœ¨ç»Ÿä¸€å…¥å£ä¸‹å®Œæˆè·¨å¹³å°å†…å®¹é‡‡é›†ã€ç»“æ„åŒ–æŠ½å–ã€ç½®ä¿¡åº¦è¯„ä¼°ä¸æŒä¹…åŒ–è¾“å‡ºï¼Œæ”¯æŒåç»­æ¥å…¥ MCP / Skill / Agent / Bot çš„æ ‡å‡†åŒ–ç»“æœæµã€‚

## å½“å‰å®ç°èƒ½åŠ›ï¼ˆæŒ‰ä»£ç å®é™…ï¼‰

- è·¯ç”±ä¸é‡‡é›†å™¨ï¼š`twitter/x`, `reddit`, `youtube`, `bilibili`, `telegram`, `wechat`, `xiaohongshu`, `rss`, `generic web`
- é‡‡é›†ç­–ç•¥ï¼š
  - Twitterï¼šFxTwitter + Nitter å…œåº•
  - Redditï¼šå…¬å¼€ JSON API
  - YouTubeï¼šå­—å¹•ä¼˜å…ˆï¼Œç¼ºå¤±æ—¶å¯å›é€€åˆ°éŸ³é¢‘è½¬å†™ï¼ˆ`GROQ_API_KEY`ï¼‰
  - Bilibiliï¼šå®˜æ–¹ API
  - Telegramï¼šTelethonï¼ˆéœ€è¦ `TG_API_ID` / `TG_API_HASH`ï¼‰
  - WeChat / Xiaohongshuï¼šJina å…œåº•ï¼Œæ”¯æŒ Playwright Session å›é€€
  - RSSï¼šå– feed æœ€æ–°æ¡ç›®
  - é€šç”¨ç½‘é¡µï¼šTrafilatura/BeautifulSoupï¼Œå¤±è´¥æ—¶å¯å›é€€ Firecrawlï¼ˆ`FIRECRAWL_API_KEY`ï¼‰
- åŒå±‚è¾“å‡ºï¼š
  - ç»“æ„åŒ– JSONï¼ˆç»Ÿä¸€ `DataPulseItem`ï¼‰
  - å¯é€‰ Markdown è®°å¿†å†™å…¥ï¼ˆ`datapulse-inbox.md` / è‡ªå®šä¹‰è·¯å¾„ï¼‰
- åˆ†æ•°ä¸ç½®ä¿¡ï¼šåŸºäºè§£æå™¨å¯é æ€§ã€æ ‡é¢˜/æ­£æ–‡é•¿åº¦/æ¥æº/ä½œè€…/æ ‡ç­¾ä¸ç‰¹å¾ï¼Œæœ€ç»ˆè¿”å› 0.01~0.99 åŒºé—´
- ç¨³å¥æ€§ï¼š
  - ç»Ÿä¸€é”™è¯¯å¤„ç†
  - å¹¶å‘æ‰¹é‡æ‰§è¡Œï¼ˆ`read_batch`ï¼‰
  - å»é‡ä¸è¿‡æœŸè£å‰ªï¼ˆé»˜è®¤æœ€å¤š 500 æ¡ã€30 å¤©ï¼‰

## å®‰è£…

```bash
pip install -e .
pip install -e ".[all]"   # å¯ç”¨å…¨éƒ¨å¯é€‰èƒ½åŠ›
```

å¯é€‰åˆ†ç»„ï¼š

- `.[trafilatura]`ã€`.[youtube]`ã€`.[telegram]`ã€`.[browser]`ã€`.[mcp]`ã€`.[notebooklm]`

## è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ã€ŒDataPulse Non-Commercial License v1.0ã€ã€‚
ä»…å…è®¸éå•†ä¸šç”¨é€”ï¼ˆæ•™å­¦ã€ç§‘ç ”ã€ä¸ªäººç ”ç©¶ã€å†…éƒ¨è¯„ä¼°ç­‰ï¼‰å†…å…è´¹ä½¿ç”¨ï¼›å•†ä¸šä½¿ç”¨è¯·è”ç³»ä½œè€…è·å–å•†ä¸šæˆæƒã€‚

è¯¦ç»†æ¡æ¬¾è¯·æŸ¥çœ‹ä»“åº“æ ¹ç›®å½• `LICENSE` æ–‡ä»¶ã€‚

## å¿«é€Ÿå¼€å§‹

### 1) CLI åŸºç¡€ç”¨æ³•

```bash
# è§£æå•æ¡ URL
datapulse https://x.com/xxxx/status/123

# æ‰¹é‡è§£æï¼ˆå¹¶å‘ï¼‰
datapulse --batch https://x.com/... https://www.reddit.com/... --min-confidence 0.45

# åˆ—å‡ºå†…å­˜ï¼ˆæŒ‰ç½®ä¿¡é™åºï¼‰
datapulse --list --limit 10 --min-confidence 0.30

# ç™»å½•çŠ¶æ€é‡‡é›†ï¼ˆç”¨äºç™»å½•ååœºæ™¯ï¼‰
datapulse --login xhs
datapulse --login wechat

# æ¸…ç©ºå†…å­˜
datapulse --clear
```

### 2) Smoke æµ‹è¯•å‘½ä»¤

```bash
# ä»…åˆ—å‡ºéœ€è¦é…ç½®çš„ç¯å¢ƒå˜é‡
datapulse-smoke --list

# æŒ‰å¹³å°å›å½’
datapulse-smoke --platforms xhs wechat --require-all

# è¿è¡Œå…¨éƒ¨åœºæ™¯ï¼ˆå¯è®¾ç½®ç½®ä¿¡é˜ˆå€¼ï¼‰
datapulse-smoke --min-confidence 0.45
```

`datapulse-smoke` çš„ç¯å¢ƒå˜é‡è¾“å…¥é¡¹ï¼š

- `DATAPULSE_SMOKE_TWITTER_URL`
- `DATAPULSE_SMOKE_REDDIT_URL`
- `DATAPULSE_SMOKE_YOUTUBE_URL`
- `DATAPULSE_SMOKE_BILIBILI_URL`
- `DATAPULSE_SMOKE_TELEGRAM_URL`
- `DATAPULSE_SMOKE_RSS_URL`
- `DATAPULSE_SMOKE_WECHAT_URL`
- `DATAPULSE_SMOKE_XHS_URL`

## MCP / Skill / Agent ä½¿ç”¨

- MCP æœåŠ¡ç«¯ï¼ˆéœ€å®‰è£… `.[mcp]`ï¼‰ï¼š

```bash
python -m datapulse.mcp_server
```

æš´éœ²å·¥å…·ï¼š

- `read_url(url, min_confidence=0.0)`
- `read_batch(urls, min_confidence=0.0)`
- `query_inbox(limit=20, min_confidence=0.0)`
- `detect_platform(url)`
- `health()`

- Skill å…¥å£ï¼ˆå¯ä¾› OpenClaw Skill æ¥å…¥ï¼‰ï¼š

```python
from datapulse_skill import run
run("è¯·å¤„ç†è¿™äº›ä¿¡æ¯: https://x.com/... æˆ– https://reddit.com/...")
```

- Agent è°ƒç”¨ï¼ˆå¯è¢«ä¸Šå±‚ Bot æ¡†æ¶å°è£…ï¼‰ï¼š

```python
from datapulse.agent import DataPulseAgent

agent = DataPulseAgent(min_confidence=0.25)
result = await agent.handle("https://x.com/... and https://www.reddit.com/...")
```

## é…ç½®ä¸ç¯å¢ƒå˜é‡

- `INBOX_FILE`
- `DATAPULSE_MEMORY_DIR`
- `DATAPULSE_KEEP_DAYS`ï¼ˆé»˜è®¤ 30ï¼‰
- `DATAPULSE_MAX_INBOX`ï¼ˆé»˜è®¤ 500ï¼‰
- `OUTPUT_DIR`
- `DATAPULSE_MARKDOWN_PATH`
- `OBSIDIAN_VAULT`
- `DATAPULSE_SESSION_DIR`ï¼ˆé»˜è®¤ `~/.datapulse/sessions`ï¼‰
- `TG_API_ID` / `TG_API_HASH`
- `NITTER_INSTANCES`
- `FXTWITTER_API_URL`
- `FIRECRAWL_API_KEY`
- `GROQ_API_KEY`
- `DATAPULSE_SMOKE_*`
- `DATAPULSE_MIN_CONFIDENCE`

## ä½¿ç”¨å»ºè®®ï¼ˆopenclaw-bot åœºæ™¯ï¼‰

- MCP ä¾§å»ºè®®ç”¨ `read_url/read_batch` äº§ç”Ÿç»“æ„åŒ– JSONï¼ŒæŒ‰ `source_type/confidence/tags` åšäºŒæ¬¡è·¯ç”±ã€‚
- Skill ä¾§å»ºè®®ç”¨ `DataPulseItem` çš„ `to_dict()` ç»“æœç›´æ¥å…¥é˜Ÿï¼Œé¿å…å¤å†™è§£æé€»è¾‘ã€‚
- Agent ä¾§å»ºè®®åœ¨å¯¹è¯ä¸­å…ˆæŠ½ URLï¼Œå†è°ƒç”¨ `agent.handle` åšæ‰¹é‡æ‰¹æ³¨ä¸é™ç½®ä¿¡ã€‚
- ç»Ÿä¸€è®°å¿†è·¯å¾„å»ºè®®é…ç½®ç‹¬ç«‹ç›®å½•ï¼Œä¾¿äº Bot å¤šå®ä¾‹å…±äº«å·²é‡‡é›†ç»“æœã€‚

## å®‰å…¨ä¸è¾¹ç•Œ

- å½“å‰å®ç°å¯¹ URL åšåŸºç¡€å¯è¾¾æ€§ä¸åŸŸåç­–ç•¥æ ¡éªŒï¼ˆæ‹¦æˆªå†…ç½‘/æœ¬åœ°åœ°å€ä¸éå…¬ç½‘è§£æï¼‰ã€‚
- `read_batch` é»˜è®¤è·³è¿‡å•æ¡å¤±è´¥ï¼Œ`return_all=False` å¯æ”¹ä¸ºé‡é”™å³æŠ›ã€‚

## è¯´æ˜

- ä»“åº“æ–‡æ¡£ä¸åŒ…å«æœ¬åœ°æµ‹è¯•ç¯å¢ƒä¸æ¨¡å‹ç«¯ç‚¹æ˜æ–‡ä¿¡æ¯ã€‚
- æ•æ„Ÿé…ç½®éœ€æ”¾å…¥ä½ çš„ç§æœ‰è¿è¡Œæ—¶ç¯å¢ƒï¼Œé€šè¿‡å®‰å…¨å‡­è¯ç®¡ç†æ–¹å¼æ³¨å…¥ã€‚

## OpenClaw å¯¹æ¥èµ„äº§ï¼ˆå»ºè®®ï¼‰

- å·¥å…·å¥‘çº¦æ¨¡æ¿ï¼š`docs/contracts/openclaw_datapulse_tool_contract.json`
- å¿«é€ŸéªŒæ”¶è„šæœ¬ï¼š`scripts/datapulse_local_smoke.sh`ã€`scripts/datapulse_remote_openclaw_smoke.sh`
- å‘å¸ƒæ¸…å•ï¼š`docs/release_checklist.md`

```bash
chmod +x scripts/datapulse_local_smoke.sh scripts/datapulse_remote_openclaw_smoke.sh
export URL_1="https://x.com/xxxx/status/123"
export URL_BATCH="https://x.com/... https://www.reddit.com/..."
bash scripts/datapulse_local_smoke.sh
# è¿œç«¯ï¼ˆéœ€å…ˆé…ç½® VPS/M4 è¿æ¥å˜é‡ï¼‰
bash scripts/datapulse_remote_openclaw_smoke.sh
```

## å‘å¸ƒä¸ç‰ˆæœ¬ç»‘å®šï¼ˆReleaseï¼‰

- å‘å¸ƒèµ„äº§ï¼š
  - `python -m build --sdist --wheel .`
  - é™„åŠ  `dist/*.whl` ä¸ `dist/*.tar.gz`
- è‡ªåŠ¨åŒ–ï¼š
  - `./scripts/release_publish.sh --tag vX.Y.Z`
  - æ¨é€ tag åç”± `.github/workflows/release.yml` è‡ªåŠ¨é™„åŠ èµ„äº§åˆ° GitHub Release

[ğŸ”¼ å›åˆ°é¡¶éƒ¨](#top) | [ğŸ‡¨ğŸ‡³ ä¸­æ–‡è¯¦æƒ…é¡µ](./README_CN.md) | [ğŸ‡ºğŸ‡¸ English details](./README_EN.md)

</details>

---

<a id="top"></a>

<details>
<summary><b>ğŸ‡ºğŸ‡¸ English</b></summary>

## Core goal

Build a single intake path for URL content extraction, confidence scoring, and memory output,
with structured results that can feed MCP, Assistant Skill, Agent, or Bot workflows.

## Implemented capabilities

- Router and collectors: `twitter/x`, `reddit`, `youtube`, `bilibili`, `telegram`, `wechat`, `xiaohongshu`, `rss`, `generic web`
- Collector strategy:
  - Twitter: FxTwitter primary + Nitter fallback
  - Reddit: public JSON API
  - YouTube: transcript first, optional audio transcription fallback (`GROQ_API_KEY`)
  - Bilibili: official API
  - Telegram: Telethon (`TG_API_ID` / `TG_API_HASH`)
  - WeChat / Xiaohongshu: Jina fallback, optional Playwright session fallback
  - RSS: latest feed item
  - Generic web: Trafilatura / BeautifulSoup, optional Firecrawl fallback (`FIRECRAWL_API_KEY`)
- Output:
  - Structured JSON (`DataPulseItem`)
  - Optional Markdown output (`datapulse-inbox.md` / custom path)
- Scoring:
  - parser reliability + content/title/metadata features, bounded to [0.01, 0.99]
- Resilience:
  - unified parse result handling
  - concurrent batch read (`read_batch`)
  - dedupe and prune by max items / retention days

## Install

```bash
pip install -e .
pip install -e ".[all]"   # enable all optional capabilities
```

Optional groups:

- `.[trafilatura]`, `.[youtube]`, `.[telegram]`, `.[browser]`, `.[mcp]`, `.[notebooklm]`

## License

This project is released under the **DataPulse Non-Commercial License v1.0**.
It is free for non-commercial use (e.g., education, research, personal/POC evaluation).
Commercial usage requires a separate license from the author.

See the root `LICENSE` file for full terms.

## Quick start

### 1) CLI basics

```bash
# read one URL
datapulse https://x.com/xxxx/status/123

# batch read
datapulse --batch https://x.com/... https://www.reddit.com/... --min-confidence 0.45

# list memory in confidence order
datapulse --list --limit 10 --min-confidence 0.30

# store login sessions when needed
datapulse --login xhs
datapulse --login wechat

# clear memory
datapulse --clear
```

### 2) Smoke check

```bash
# show required environment keys for smoke tests
datapulse-smoke --list

# run selected platforms
datapulse-smoke --platforms xhs wechat --require-all

# run all configured scenarios
datapulse-smoke --min-confidence 0.45
```

Smoke env vars:

- `DATAPULSE_SMOKE_TWITTER_URL`
- `DATAPULSE_SMOKE_REDDIT_URL`
- `DATAPULSE_SMOKE_YOUTUBE_URL`
- `DATAPULSE_SMOKE_BILIBILI_URL`
- `DATAPULSE_SMOKE_TELEGRAM_URL`
- `DATAPULSE_SMOKE_RSS_URL`
- `DATAPULSE_SMOKE_WECHAT_URL`
- `DATAPULSE_SMOKE_XHS_URL`

## MCP / Skill / Agent

- MCP server (install with `.[mcp]`):

```bash
python -m datapulse.mcp_server
```

Exposed tools:

- `read_url(url, min_confidence=0.0)`
- `read_batch(urls, min_confidence=0.0)`
- `query_inbox(limit=20, min_confidence=0.0)`
- `detect_platform(url)`
- `health()`

- Skill entry (for OpenClaw/assistant adapters):

```python
from datapulse_skill import run
run("Please process: https://x.com/... and https://www.reddit.com/...")
```

- Agent usage:

```python
from datapulse.agent import DataPulseAgent

agent = DataPulseAgent(min_confidence=0.25)
result = await agent.handle("https://x.com/... and https://www.reddit.com/...")
```

## Config and env vars

- `INBOX_FILE`
- `DATAPULSE_MEMORY_DIR`
- `DATAPULSE_KEEP_DAYS` (default 30)
- `DATAPULSE_MAX_INBOX` (default 500)
- `OUTPUT_DIR`
- `DATAPULSE_MARKDOWN_PATH`
- `OBSIDIAN_VAULT`
- `DATAPULSE_SESSION_DIR` (default `~/.datapulse/sessions`)
- `TG_API_ID` / `TG_API_HASH`
- `NITTER_INSTANCES`
- `FXTWITTER_API_URL`
- `FIRECRAWL_API_KEY`
- `GROQ_API_KEY`
- `DATAPULSE_SMOKE_*`
- `DATAPULSE_MIN_CONFIDENCE`

## Recommended usage for bot/agent stacks

- MCP: call `read_url/read_batch` and route by `source_type + confidence` before tool selection.
- Skill: use returned summaries or raw `DataPulseItem.to_dict()` directly to avoid re-parsing.
- Agent: extract URLs from text first, then call `DataPulseAgent.handle` for batched processing.
- Keep memory path stable across nodes if your bot runtime needs shared cache.

## Security and boundaries

- URL routing applies public-network checks and blocks obvious local/private targets.
- `read_batch` skips failed entries by default; set strict failure behavior by code as needed.

## OpenClaw integration assets

- Tool contract: `docs/contracts/openclaw_datapulse_tool_contract.json`
- Quick validation scripts: `scripts/datapulse_local_smoke.sh`, `scripts/datapulse_remote_openclaw_smoke.sh`
- Release checklist: `docs/release_checklist.md`

```bash
chmod +x scripts/datapulse_local_smoke.sh scripts/datapulse_remote_openclaw_smoke.sh
export URL_1="https://x.com/xxxx/status/123"
export URL_BATCH="https://x.com/... https://www.reddit.com/..."
bash scripts/datapulse_local_smoke.sh
# remote execution requires VPS tunnel
bash scripts/datapulse_remote_openclaw_smoke.sh
```

## Release and publishing

- Build artifacts:
  - `python -m build --sdist --wheel .`
  - Upload `dist/*.whl` and `dist/*.tar.gz`
- Release automation:
  - `./scripts/release_publish.sh --tag vX.Y.Z`
  - GitHub Actions auto-publishes assets on tag push via `.github/workflows/release.yml`

## Notes

- Repository docs do not include local test environment or model endpoint plaintext.
- Keep sensitive runtime configuration outside repository and inject via private environment management.

[ğŸ”¼ Back to top](#top) | [ğŸ‡¨ğŸ‡³ ä¸­æ–‡è¯¦æƒ…é¡µ](./README_CN.md) | [ğŸ‡ºğŸ‡¸ English details](./README_EN.md)

</details>
